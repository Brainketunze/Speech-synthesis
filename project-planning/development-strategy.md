# Project Title: Speech syhthesis

project description

Speech synthesis is one half of the Web Speech API, the other being the speech recognition API we dealt with earlier. Speech synthesis is accessed via the SpeechSynthesis interface, a text-to-speech component that allows programs to read out their text content (normally via the device's default speech synthesizer.) Different voice types are represented by SpeechSynthesisVoice objects, and different parts of text that you want to be spoken are represented by SpeechSynthesisUtterance objects. You can get these spoken by passing them to the SpeechSynthesis.speak() method. Is an app that speak whatever text mesage is initialise in the text area.

## User Story Dependencies

[Story Dependency Diagram](https://excalidraw.com/)

---

## WIREFRAME

![wireframe or figma]()

---

## 0.Setup

---

## X. Story Name

> how much work do you think this step will take? small, medium, large?

**As a user I want to \_\_\_ so that \_\_\_**

- [ ] _Given [context] when [a specific action is performed] then [a set of consequences should occur]_
- [ ] ...

### REPO

- This user story is developed on branch `_`.
- This branch is merged to `master` branch after the acceptance criteria have been checked off.

### Concern A

- `file-name.js`: what is this file for? who is it assigned to?

### Concern B

- `file-name.js`: what is this file for? who is it assigned to?

### ...

---

## ...
